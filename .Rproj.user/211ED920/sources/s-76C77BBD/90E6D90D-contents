### Libraries

library(caret)
library(fda)
library(fda.usc)
library(dplyr)

### Data
### Establish a clear set of inputs that can be used generally for statistical estimation.
### We can also start working to establish .Rdata files that have the data frame stored correctly.

data.raw <- read.table('lupustherm.txt')
temperatures <- seq(45, 90, 0.1)
thermogram.length <- length(temperatures)

samples.n <- dim(data.raw)[1]

thermograms.raw <- data.raw %>% select(1:thermogram.length)
class.raw <- data.raw %>% select(-(1:thermogram.length))

### Provide Names for any columns that are classifiers information.  So here, we indicate lupus/non-lupus

colnames(class.raw) <- 'SLE'
class.raw$SLE <- factor(class.raw$SLE)

### Visualization
### We can probably produce some nice visualization using ggplot.

# cols = rainbow(samples.n)
# plot(temperatures, thermograms.raw[1,], type='l', ylim = c(-0.25, 0.5), col=cols[1])
# for(i in 2:samples.n) lines(temperatures, thermograms.raw[i,], col=cols[i])

### Functional Data
### To be used for smoothing and derivatives

fdata.raw <- fdata(thermograms.raw, argvals=temperatures)
plot(fdata.raw)

######## Smoothing ############

### Choose a Basis

# full.spline <- create.bspline.basis(range=range(temperatures), nbasis = thermogram.length+2)

### We can tune from basis = 2 to length(argvals))
basis <- 125 ### Tuneable, if basis=length(arvals) then use raw.
reduced.basis.spline <- create.bspline.basis(range=range(temperatures), nbasis = basis+2)
Smoothing.Matrix <- S.basis(temperatures, basis=reduced.basis.spline)

fdata.smooth <- fdata.raw
fdata.smooth$data <- fdata.raw$data%*%Smoothing.Matrix
plot(fdata.smooth)

cbind(fdata.smooth$data[,1], fdata.raw$data[,1])

fdata.working <- fdata.smooth ### Working functional data set
toolkit.ws <- data.frame(Class = class.raw$SLE, X = fdata.working$data)  ### data.frame ws
colnames(toolkit.ws) <- c('Class', temperatures)

################################
### Data flow/cleaning is all above.
### Below is me starting to work on functions that should call the working data set.
################################

######### Function #############

## I will start by doing something outside the scope of 578.  I will use Penalized-LDA

library('penalizedLDA')

fdata.working <- fdata.raw ### Working functional data set

x <- fdata.working$data
dim(x)
y <- as.numeric(class.raw$SLE)
penlda.cv.out <- PenalizedLDA.cv(x=x, y=y)

lambda.seq <- exp(seq(-6, 2, 0.01))  ### This could be an input, best to suggest evalauating this outide of functions.
penlda.cv.out <- PenalizedLDA.cv(x=x, y=y, lambdas=lambda.seq, nfold = 10)

plot(penlda.cv.out)
penlda.cv.out$bestlambda

### The start of a function

# set.seed(10)
# 
# folds.all <- caret::createFolds(class.raw$SLE)
# lambda.seq <- exp(seq(-6, 2, 0.01))  ### This could be an input, best to suggest evalauating this outide of functions.
# 
# 
# 
# fold.id <- 2
# 
# folds.all[[fold.id]]
# 
# x.test <- x[folds.all[[fold.id]],]
# y.test <- y[folds.all[[fold.id]]]
# 
# x.train <- x[-folds.all[[fold.id]],]
# y.train <- y[-folds.all[[fold.id]]]
# 
# penlda.cv.out <- PenalizedLDA.cv(x=x.train, y=y.train, lambdas=lambda.seq, nfold = 10)
# 
# lambda.set <- penlda.cv.out$bestlambda
# 
# penlda.out <- PenalizedLDA(x=x.train, y=y.train, lambda=lambda.set, K=1)
# 
# plot(penlda.out$discrim)
# probs <- 1/(1+exp(-x.test%*%penlda.out$discrim))/()
# predict.test <- probs>0.5
# factor(predict.test, c(TRUE, FALSE), c(0,1))
# y.test-1
# 
# table(y.test-1, predict.test)
# mean(y.test-1==predict.test)
# 
# cbind(probs, penlda.preds$ypred)
# 
# penlda.preds <- predict(penlda.out, x.test)
# acc <- mean(penlda.preds$ypred==y.test)  ### There does not seem to be a way to get posterior probabilities, so we may not include this

### A loop

set.seed(10)

folds.n <- 10
folds.all <- caret::createFolds(class.raw$SLE, k = folds.n)
lambda.seq <- exp(seq(-6, 2, 0.01))  ### This could be an input, best to suggest evalauating this outide of functions.
acc <- vector()

for(fold.id in 1:folds.n)
{
  x.test <- x[folds.all[[fold.id]],]
  y.test <- y[folds.all[[fold.id]]]
  
  x.train <- x[-folds.all[[fold.id]],]
  y.train <- y[-folds.all[[fold.id]]]
  
  penlda.cv.out <- PenalizedLDA.cv(x=x.train, y=y.train, lambdas=lambda.seq, nfold = 10)
  
  lambda.set <- penlda.cv.out$bestlambda
  
  penlda.out <- PenalizedLDA(x=x.train, y=y.train, lambda=lambda.set, K=1)
  
  penlda.preds <- predict(penlda.out, x.test)
  acc[fold.id] <- mean(penlda.preds$ypred==y.test)  ### There does not seem to be a way to get posterior probabilities, so we may not include this
}

boxplot(acc)  ### Got about 72% mean test set accuracy in first run, on a smoothed set
## Second run was on original data, seemed different, tuning should be interesting.

### Enforcing a fused penalty
### This is something of interest but takes double the tuning (so probably quadruple the effort)

# set.seed(10)
# 
# folds.n <- 10
# folds.all <- caret::createFolds(class.raw$SLE, k = folds.n)
# lambda.seq <- exp(seq(-6, 2, 0.01))  ### This could be an input, best to suggest evalauating this outide of functions.
# acc <- vector()
# 
# for(fold.id in 1:folds.n)
# {
#   x.test <- x[folds.all[[fold.id]],]
#   y.test <- y[folds.all[[fold.id]]]
#   
#   x.train <- x[-folds.all[[fold.id]],]
#   y.train <- y[-folds.all[[fold.id]]]
#   
#   penlda.cv.out <- PenalizedLDA.cv(x=x.train, y=y.train, lambdas=lambda.seq, nfold = 10, type='ordered')
#   
#   lambda.set <- penlda.cv.out$bestlambda
#   
#   penlda.out <- PenalizedLDA(x=x.train, y=y.train, lambda=lambda.set, K=1, type='ordered')
#   
#   penlda.preds <- predict(penlda.out, x.test)
#   acc[fold.id] <- mean(penlda.preds$ypred==y.test)  ### There does not seem to be a way to get posterior probabilities, so we may not include this
# }
# 
# boxplot(acc)  ### Got about 72% mean test set accuracy in first run
